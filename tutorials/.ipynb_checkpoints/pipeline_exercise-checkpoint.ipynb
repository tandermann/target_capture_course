{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline exercise\n",
    "\n",
    "Fortunately there are computational pipelines which enable you to process many samples jointly and which make the whole workflow more user-friendly. These pipelines also help to produce a consistent, documented and therefore reproducible workflow. Here we are going to use the [SECAPR pipeline](https://github.com/AntonelliLab/seqcap_processor) on a dataset of **Ultraconserved Elements (UCEs)** that were samples for the  in South America.\n",
    "\n",
    "![img.png](./img/topaza_distribution_sampling_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not clear if the existing morphological species assignments are justified and if there might be cryptic species within these morphospecies. We want to use this UCE dataset to generate a phylogeny (species tree) of these samples to define coalescent species and see if these assignments are in agreement with population genetics analyses using SNP data extracted from the UCEs.\n",
    "\n",
    "In this tutorial you'll go through the following steps:\n",
    "\n",
    "\n",
    "![](./img/secapr_workflow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________\n",
    "\n",
    "**0)** Let's first make sure that we are connected to the correct software environment (`forbio_env`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "module load Anaconda3/5.1.0\n",
    "source activate forbio_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_______\n",
    "\n",
    "**1)** Then copy the pipeline tutorial folder into your directory at `/work/users/USERNAME/`.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "This is not your default home directory! Make sure you really work at `/work/users/USERNAME/`\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp -r /work/projects/forbio/tutorials_tobi/pipeline/ /work/users/USERNAME/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______\n",
    "\n",
    "**2)** Now let's run the cleaning and trimming script for all of your samples.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "We are appending `2> warnings.txt` to all following commands because the cluster is printing a lot of annoying warning messages when loading some of the SECAPR dependencies. This command will silence those warnings and print them into the file `warnings.txt`\n",
    "</div>\n",
    "\n",
    "Every command has a help function that shows you the available options. Check out the help function of `secapr clean_reads`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr clean_reads -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the cleaning and trimming with this command. Feel free to add any flags you feel are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr clean_reads --input raw_reads/ --config helpfiles/adapters_info_topaza.txt --output cleaned_reads --index single --headCrop 10 2> warnings.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it is running **INTERRUPT THIS COMMAND** using `ctrl+c`. Since it will take around 30 minutes to clean all the samples, we instead submit this as a job script. You find the job script in the `scripts` folder. Fill in the correct paths and submit it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sbatch scripts/clean_trim_secapr.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______\n",
    "\n",
    "**3)** You can check the quality of the cleaned reads for all samples using the `secapr quality_check` command. This will create a plot `QC_plots.pdf` with an overview of the failed and passed test of all samples (you can skip this step for this exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr quality_check --input cleaned_reads/ --output quality_test 2> warnings.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______\n",
    "\n",
    "**4)** Now run a de novo assembly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr assemble_reads --input ./cleaned_reads/ --output ./contigs_abyss --assembler abyss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______\n",
    "\n",
    "**5)** Extract the target regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr find_target_contigs --contigs contigs_abyss/ --reference helpfiles/Tetrapods-UCE-2.5Kv1.fasta --output target_contigs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output folder and have a look at the `match_table.txt` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______\n",
    "\n",
    "**6)** Build multiple sequence alignments (MSAs) between all our samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr align_sequences --sequences target_contigs/extracted_target_contigs_all_samples.fasta --output alignments/contig_alignments/ --aligner mafft --output-format fasta --no-trim --ambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______\n",
    "\n",
    "**7)** Now we run the reference assembly, using the consensus sequence of each of our assembled contig multiple sequence alignments (MSAs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr reference_assembly --reads cleaned_reads --reference_type alignment-consensus --reference alignments/contig_alignments --output remapped_reads --min_coverage 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect some of the files again using `samtools tview`.\n",
    "\n",
    "______\n",
    "\n",
    "**8)** You can use the `secapr locus_selection` function to find the loci that were assmebled across all samples. You can set the number of extracted loci very high, to ensure that all loci that are present in all samples will be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr locus_selection --input remapped_reads --output locus_selection/ --n 2000 --read_cov 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______\n",
    "\n",
    "**9)** Now we can build alignments from these loci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr align_sequences --sequences locus_selection/joined_fastas_selected_loci.fasta --output alignments/exon_intron_alignments/ --aligner mafft --output-format fasta --no-trim --ambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between these alignments and the ones we created in step **6)** ?\n",
    "\n",
    "\n",
    "______\n",
    "\n",
    "**10)** SECAPR also has a function that enables allele phasing. This will produce two separate BAM files per samples which in tunr can be summarized into two separate sequences (allele sequences) per sample and locus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr phase_alleles --input remapped_reads/ --output allele_sequences --min_coverage 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______\n",
    "\n",
    "**11)** Finally we can use the phased BAM files to generate allele sequence alignments (MSAs) for all samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "secapr align_sequences --sequences allele_sequences/joined_allele_fastas.fasta --output alignments/allele_alignments/ --aligner mafft --output-format fasta --no-trim --ambiguous"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
